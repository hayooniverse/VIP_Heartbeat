<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Video Capture Example</title>
<link href="js_example_style.css" rel="stylesheet" type="text/css" />
</head>
<body>
<h2>Video Capture Example</h2>
<p>
    Click <b>Start/Stop</b> button to start or stop the camera capture.<br>
    The <b>videoInput</b> is a &lt;video&gt; element used as OpenCV.js input.
    The <b>canvasOutput</b> is a &lt;canvas&gt; element used as OpenCv.js output.<br>
    The code of &lt;textarea&gt; will be executed when video is started.
    You can modify the code to investigate more.
</p>
<div>
<div class="control"><button id="startAndStop" disabled>Start</button></div>
<textarea class="code" rows="29" cols="100" id="codeEditor" spellcheck="false">
</textarea>
</div>
<p class="err" id="errorMessage"></p>
<div>
    <table cellpadding="0" cellspacing="0" width="0" border="0">
    <tr>
        <td>
            <video id="videoInput" width=320 height=240></video>
        </td>
        <td>
            <canvas id="canvasOutput" width=320 height=240></canvas>
        </td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>
            <div class="caption">videoInput</div>
        </td>
        <td>
            <div class="caption">canvasOutput</div>
        </td>
        <td></td>
        <td></td>
    </tr>
    </table>
</div>
<script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
<script src="utils.js" type="text/javascript"></script>
<script src="utils_algo.js" type="text/javascript"></script>
<script id="codeSnippet" type="text/code-snippet">
let video = document.getElementById('videoInput');
let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
let webcam = new cv.VideoCapture(video);

// Helper Methods
function pyrDown(src) {
    let dst = new cv.Mat();
    cv.pyrDown(src, dst);
    return dst;
}

function buildGauss(src, levels) {
    let pyramid = [src];
    let currentLevel = src;
    for (let level = 1; level <= levels; level++) {
        let down = new cv.Mat();
        cv.pyrDown(currentLevel, down);
        pyramid.push(down);
        currentLevel = down;
    }
    return pyramid;
}
function reconstructFrame(pyramid, index, levels, videoHeight, videoWidth) {
    let filteredFrame = pyramid[index].clone();
    for (let level = 0; level < levels; level++) {
        let up = new cv.Mat();
        cv.pyrUp(filteredFrame, up);
        filteredFrame.delete(); // Delete the previous frame to free memory
        filteredFrame = up;
    }
    // Ensure the resulting frame matches the original video dimensions.
    // This is necessary because repeated pyrUp operations may result in a slightly different size due to rounding.
    let resizedFrame = new cv.Mat();
    let size = new cv.Size(videoWidth, videoHeight);
    cv.resize(filteredFrame, resizedFrame, size, 0, 0, cv.INTER_LINEAR);
    filteredFrame.delete(); // Free memory
    return resizedFrame;
}



const FPS = 30;
function processVideo() {
    try {
        if (!streaming) {
            // clean and stop.
            src.delete();
            if (dst) dst.delete(); // Delete dst if it's used for something else
            return;
        }
        let begin = Date.now();
        // Start processing.
        webcam.read(src);
        // If you need dst for other operations, clone src to dst or use it directly.
        // cv.cvtColor(src, dst, cv.COLOR_RGBA2RGBA); // This line would effectively just clone src to dst, and is unnecessary if you're only displaying the src.
        cv.imshow('canvasOutput', src); // Display the original color frame
        
        // Draw ROI
        const centerX = video.width / 2;
        const centerY = video.height / 2;
        const rectWidth = 100;
        const rectHeight = 50;
        const startPoint = new cv.Point(centerX - rectWidth / 2, centerY - rectHeight / 2);
        const endPoint = new cv.Point(centerX + rectWidth / 2, centerY + rectHeight / 2);
        let rectColor = new cv.Scalar(0, 255, 0, 255); // RGBA for green
        cv.rectangle(src, startPoint, endPoint, rectColor, 2, cv.LINE_8, 0);

        // Define Detection Frame
        let rect = new cv.Rect(startPoint.x, startPoint.y, rectWidth, rectHeight);
        let detectionFrame = src.roi(rect);

        // Initialize Gaussian Pyramid
        


        cv.imshow('canvasOutput', src);

        // Schedule the next one.
        let delay = 1000/FPS - (Date.now() - begin);
        setTimeout(processVideo, delay);
    } catch (err) {
        utils.printError(err);
    }
};


// schedule the first one.
setTimeout(processVideo, 0);
</script>
<script type="text/javascript">
let utils = new Utils('errorMessage');

utils.loadCode('codeSnippet', 'codeEditor');

let streaming = false;
let videoInput = document.getElementById('videoInput');
let startAndStop = document.getElementById('startAndStop');
let canvasOutput = document.getElementById('canvasOutput');
let canvasContext = canvasOutput.getContext('2d');

startAndStop.addEventListener('click', () => {
    if (!streaming) {
        utils.clearError();
        utils.startCamera('qvga', onVideoStarted, 'videoInput');
    } else {
        utils.stopCamera();
        onVideoStopped();
    }
});

function onVideoStarted() {
    streaming = true;
    startAndStop.innerText = 'Stop';
    videoInput.width = videoInput.videoWidth;
    videoInput.height = videoInput.videoHeight;
    utils.executeCode('codeEditor');
}

function onVideoStopped() {
    streaming = false;
    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
    startAndStop.innerText = 'Start';
}

utils.loadOpenCv(() => {
    startAndStop.removeAttribute('disabled');
});
</script>
</body>
</html>